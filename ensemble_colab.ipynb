{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4e29eb",
   "metadata": {},
   "source": [
    "### ðŸ’¡ Instructions\n",
    "- Upload your `dataset/` and `models/` folders to the Colab environment.\n",
    "- Adjust paths to match your directory structure (e.g., `'dataset/train.csv'`).\n",
    "- Run cells to train, evaluate, or predict using the ensemble model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bdde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e25b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from dataset.dataset import get_dataloaders\n",
    "from models.plain_bert import PlainBertClassifier\n",
    "from models.roberta_classifier import RobertaClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aef33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, tokenizer, model_name, device, epochs=10, lr=2e-5):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Training {model_name} Epoch {epoch+1}\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs['loss']\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(train_loader):.4f}\")\n",
    "        torch.save(model.state_dict(), f\"{model_name}_best.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9965b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Predicting\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs['logits']\n",
    "            preds = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "    return predictions\n",
    "\n",
    "def ensemble_predictions(preds_list):\n",
    "    final_preds = []\n",
    "    for tokens in zip(*preds_list):\n",
    "        batch_preds = []\n",
    "        for token_preds in zip(*tokens):\n",
    "            vote = torch.mode(torch.tensor(token_preds)).values.item()\n",
    "            batch_preds.append(vote)\n",
    "        final_preds.append(batch_preds)\n",
    "    return final_preds\n",
    "\n",
    "def compute_metrics(predictions, labels, mask):\n",
    "    all_preds, all_labels = [], []\n",
    "    for pred, label, attn in zip(predictions, labels, mask):\n",
    "        for p, l, m in zip(pred, label, attn):\n",
    "            if m == 1:\n",
    "                all_preds.append(p)\n",
    "                all_labels.append(l)\n",
    "    return {\n",
    "        \"precision\": precision_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        \"recall\": recall_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "        \"f1\": f1_score(all_labels, all_preds, average='macro', zero_division=0),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2574bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission(predictions, filename=\"submission/prediction.csv\"):\n",
    "    df = pd.read_csv(\"dataset/eval_w_o_labels.csv\")\n",
    "    result = []\n",
    "    for i, row in df.iterrows():\n",
    "        tokenized = eval(row['tokenized_sentence'])\n",
    "        labels = predictions[i][:len(tokenized)]\n",
    "        idiom_indices = []\n",
    "        current = []\n",
    "        for j, label in enumerate(labels):\n",
    "            if label == 1:\n",
    "                if current:\n",
    "                    idiom_indices.extend(current)\n",
    "                    current = []\n",
    "                current = [j]\n",
    "            elif label == 2:\n",
    "                if current:\n",
    "                    current.append(j)\n",
    "            else:\n",
    "                if current:\n",
    "                    idiom_indices.extend(current)\n",
    "                    current = []\n",
    "        if current:\n",
    "            idiom_indices.extend(current)\n",
    "        result.append({\"id\": row['id'], \"idiom_indices\": idiom_indices if idiom_indices else [-1]})\n",
    "    pd.DataFrame(result).to_csv(filename, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0325f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_loader, val_loader, tokenizer = get_dataloaders(\n",
    "    train_path=\"dataset/train.csv\",\n",
    "    val_path=\"dataset/eval.csv\",\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "model_a = PlainBertClassifier().to(device)\n",
    "model_b = RobertaClassifier().to(device)\n",
    "\n",
    "train_model(model_a, train_loader, val_loader, tokenizer, \"plain_bert\", device)\n",
    "train_model(model_b, train_loader, val_loader, tokenizer, \"roberta\", device)\n",
    "\n",
    "model_a.load_state_dict(torch.load(\"plain_bert_best.pt\"))\n",
    "model_b.load_state_dict(torch.load(\"roberta_best.pt\"))\n",
    "\n",
    "val_loader_nolabels = DataLoader(val_loader.dataset, batch_size=8)\n",
    "\n",
    "preds_a = predict(model_a, val_loader_nolabels, device)\n",
    "preds_b = predict(model_b, val_loader_nolabels, device)\n",
    "\n",
    "final_preds = ensemble_predictions([preds_a, preds_b])\n",
    "write_submission(final_preds)\n",
    "print(\"âœ… Submission written to submission/prediction.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}