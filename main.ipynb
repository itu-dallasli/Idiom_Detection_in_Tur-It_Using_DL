{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idiom Detection with BERT + BiLSTM + CRF\n",
    "This notebook is adapted from your `main.py` for use in Google Colab.\n",
    "\n",
    "**Instructions:**\n",
    "- Upload your `model.py` and `dataset.py` files to the Colab environment.\n",
    "- Place your data in the appropriate paths (e.g., `public_data/`, `starting_kit/`).\n",
    "- Use the cells below to train, evaluate, or predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install transformers tqdm scikit-learn pytorch-crf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dataset import get_dataloaders\n",
    "from model import train_model, BertForIdiomDetection, predict_idioms\n",
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(epochs=10, lr=2e-5, batch_size=8, max_length=128):\n",
    "    train_loader, val_loader, tokenizer = get_dataloaders(\n",
    "        train_path='public_data/train.csv',\n",
    "        val_path='public_data/eval.csv',\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    model = train_model(\n",
    "        train_loader, val_loader, tokenizer,\n",
    "        epochs=epochs, lr=lr\n",
    "    )\n",
    "    print('Training complete. Best model saved as best_idiom_model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_eval(batch_size=8, max_length=128):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, val_loader, tokenizer = get_dataloaders(\n",
    "        train_path='public_data/train.csv',\n",
    "        val_path='public_data/eval.csv',\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    model = BertForIdiomDetection()\n",
    "    model.load_state_dict(torch.load('best_idiom_model.pt', map_location=device))\n",
    "    model.to(device)\n",
    "    from model import evaluate\n",
    "    metrics = evaluate(model, val_loader, tokenizer, device)\n",
    "    print('Evaluation complete.')\n",
    "    print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predict(output='predictions.csv'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = BertForIdiomDetection()\n",
    "    model.load_state_dict(torch.load('best_idiom_model.pt', map_location=device))\n",
    "    model.to(device)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "    # Read test data\n",
    "    test_df = pd.read_csv('starting_kit/eval_w_o_labels.csv')\n",
    "    ids = test_df['id'].tolist()\n",
    "    sentences = test_df['sentence'].tolist()\n",
    "    languages = test_df['language'].tolist()  # Get language information\n",
    "\n",
    "    results = []\n",
    "    for idx, sentence, lang in zip(ids, sentences, languages):\n",
    "        _, idiom_indices = predict_idioms(model, tokenizer, sentence, device)\n",
    "        # If no idiom, output [-1] as in training\n",
    "        if not idiom_indices:\n",
    "            idiom_indices = [-1]\n",
    "        results.append({\n",
    "            'id': idx,\n",
    "            'indices': str(idiom_indices),  # Convert list to string representation\n",
    "            'language': lang\n",
    "        })\n",
    "\n",
    "    out_df = pd.DataFrame(results)\n",
    "    out_df.to_csv(output, index=False)\n",
    "    print(f'Predictions saved to {output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage\n",
    "Uncomment and run the cell below for the desired operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "# run_train(epochs=10, lr=2e-5, batch_size=8, max_length=128)\n",
    "\n",
    "# Evaluate\n",
    "# run_eval(batch_size=8, max_length=128)\n",
    "\n",
    "# Predict\n",
    "# run_predict(output='predictions.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
