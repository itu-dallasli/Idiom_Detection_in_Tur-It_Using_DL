{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d439a57",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from dataset import get_dataloaders\n",
    "from transformers import AutoTokenizer\n",
    "from xlmr_model import XLMRForIdiomDetection, train_model, evaluate_model, predict_idiom_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a032be6c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_train(epochs=5, lr=3e-5, batch_size=8, max_length=128):\n",
    "    train_loader, val_loader, tokenizer = get_dataloaders(\n",
    "        train_path='dataset/train.csv',\n",
    "        val_path='dataset/eval.csv',\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    model = XLMRForIdiomDetection()\n",
    "    model = train_model(model, train_loader, val_loader, tokenizer, epochs=epochs, lr=lr)\n",
    "    os.makedirs('models/saved_pts', exist_ok=True)\n",
    "    torch.save(model.state_dict(), 'models/saved_pts/xlmr_best_model.pt')\n",
    "    print(\"Training complete. Model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c5f2d2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_eval(batch_size=8, max_length=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    _, val_loader, tokenizer = get_dataloaders(\n",
    "        train_path='dataset/train.csv',\n",
    "        val_path='dataset/eval.csv',\n",
    "        batch_size=batch_size,\n",
    "        max_length=max_length\n",
    "    )\n",
    "    model = XLMRForIdiomDetection()\n",
    "    model.load_state_dict(torch.load('models/saved_pts/xlmr_best_model.pt', map_location=device))\n",
    "    model.to(device)\n",
    "    metrics = evaluate_model(model, val_loader, tokenizer, device)\n",
    "    print(\"Evaluation complete.\\n\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2d71f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def run_predict(output_path='prediction.csv', max_length=128):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = XLMRForIdiomDetection()\n",
    "    model.load_state_dict(torch.load('xlmr_best_model.pt', map_location=device))\n",
    "    model.to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "    test_df = pd.read_csv(\"dataset/eval_w_o_labels.csv\")\n",
    "    results = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        idx = row[\"id\"]\n",
    "        sentence = row[\"sentence\"]\n",
    "        lang = row[\"language\"]\n",
    "        _, pred_indices = predict_idiom_indices(model, tokenizer, sentence, device, max_length=max_length)\n",
    "        if not pred_indices:\n",
    "            pred_indices = [-1]\n",
    "        results.append({\n",
    "            \"id\": idx,\n",
    "            \"indices\": str(pred_indices),\n",
    "            \"language\": lang\n",
    "        })\n",
    "\n",
    "    pd.DataFrame(results).to_csv(output_path, index=False)\n",
    "    print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f503667",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment to use:\n",
    "# run_train()\n",
    "# run_eval()\n",
    "# run_predict()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
